---
title: "DataSci"
author: "Ellana Pierce"
date: "2024-05-16"
output: html_document
---

1.1 Introduction
Data science is currently one of the most valued skills in the Marine Science field. This is often in the form of scripts within the Rstudio program, among others like Python and MatLAB. The ability to be able to gain an understanding into data to ask questions has grown alongside the advancements of technology and artificial intellegence within the last 10 years. I have said it before, but I'll say it again: The future is faster that we think!

To gain the skill in data science allows us to automate work flows, visualise data, share and combine data locally and globally through repositories and importantly allows our scripts and data analysis, to be reproduced in studies alike.

Gaining qualitative or quantitative data in the field, is in itself a vital aspect of science within any field. It is clear that when gathering data, a lot of aspects must be taken into account. The type of data collected, sample sizes, resources needed and how to best str

Gathering qualitative or quantitative data in the field is an essential aspect of scientific research across various disciplines. It involves careful consideration of multiple factors, including the type of data collected, sample sizes, required resources, and methodological approaches. This underscores the crucial role of data currency, where collected data not only meets scientific requirements but also translates into tangible impacts in the natural world. This is where data science plays a pivotal role, enabling the extraction of meaningful insights and trends from data sets to address pertinent questions and advance scientific understanding.

The workshop has a lot of theory based practice that is knowledge I hope to retain, so where things get wordy, that's just my way of saying "Hey! I want to remember this!"

Let's get right into it... 
Starting a R markdown script:

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
This first workshop, will be spent on building my base of scientific programmming skills in the context of making data analyses TRANSPARENT and REPRODUCIBLE.

Key takeaway: Putting into practice the abilityn to build rigorous programmed workflows and begin to put into practice, the methods for backing-up my code and implementing version control. This is important as it will teach me how best to support working collaboratively and encouraging open science principles within my own practice.

Now we can install packages that we need for the script and plots.
```{r}
install.packages("tidyverse")
library(tidyverse)
remove.packages('rlang')
install.packages('rlang')
```
We'll jump back to this later when we start to build some plots using the built in data. 

For now.. I will repeat the steps I originally used to install Git (within R), Set up a GitHub account (the online aspect and repository sharing).
We have now learnt (and will learn to appreciate) the platform known as GitHub. The version control that the platform provides is robust with its version control capabilities, where data scientists can track changes to data sets, make changes to scripts and project files. This allows for collaboration and reproduceability, two of the main themes that this technical skill focuses on!
It encourages the open science policies, that promote open access to code and data for transparency and knowledge sharing. This is also great as it means if there is curiosity about the results of research, others can reproduce the data and makesure no biases are involved in the process of the researches findings or claims!

How this actually went for us.....:
The whole class is all pretty new to Git and GitHub, except for some bioinformatics students that have had the experience with bash, git, terminal and other associated aspects we are starting to learn the skills of. 
This meant, we were in a great collaborative environment, where we were able to help eachother out. Due to the nature of the module, with Git being introduced at the beginning, instead of the end like it had in the prior year - this led to a LOT of trouble shooting, issues with software, differences between machines (e.g Macbook, linux and windows.) 

Although time consuming and frustrating, this meant we were able to really implement our time management, critical thinking, problem solving and teamwork within the first two days.

Back to it....
First we will check that everything is connected and communicating!
```{r}
#install.packages("usethis")
credentials::git_credential_ask()
usethis::git_sitrep()
```

As per the workbook instructions, I have now created a Personal Access Token (PAT)
on my account in GitHub. Here it is saved for when I need it!:

Code: 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

What now?:
I have made sure to set a new project, where I have my new script for my repository. I had previously created the cloned and personal versions but will now ONLY USE THIS ONE - to avoid confusion moving forward. 

I have now created a new project, through version control within R, copying and pasting my new repository. I have done a check that it is all connected, by 1.Committing 2. Pushing and 3. Pulling. 

I jumped online to review my repo and it's all there and looks goood. I also checked my folder and path, to makesure that it contains my code, data, output and then the project itself. They're there!!! So we can move forward now with confidence, knowing that any changes I make, will be replicated within either of the programs.


We've covered lots, but I'm gaining more of an understanding the more we put the theory into practice.


Key Actions:
2.11.1 Pull: Syncs local project from remote server (in our case - GitHub). Always save before this to avoid overwriting the file.

2.11.2 Stage: Prepares the files for being committed. Always happens before committing the files, almost like a sort and prep stage.

2.11.3 Commit: The function thast saves the version of the script/project into the repository history locally. The commment section allows us and any other users to know understand what. this comment involved. E.g "Updated changes made for raw data, cleaning and sorting. Now ready for analysis".

2.11.4 Push: The function that sends our locally commited project into the server and synchronises the versions (version control.)

PART 2: Data Visualisation in R


Let's have a looksie at our data!
```{r}
R.version.string
```
Great, we have the current and latest version of R runnning.
```{r}
install.packages("tidyverse")
library("tidyverse")
```
Install and load tidyverse packages above and then GGplot (ggplot2).
```{r}
install.packages("ggplot2")
library(ggplot2)
```
Let's start by creating a ggplot! 
A couple notes here for my portfolio!
displ- engine size of the car in litres
hwy - the car's fuel efficiency in miles per gallon (mpg). A car with a low fuel efficiency consumes more fuel than a car with a high fuel efficiency when they travel the same distance.

We will first do a scatter plot!
```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))
```
```{r}
data(mpg)
# Quick data checks
head(mpg)
glimpse(mpg)
summary(mpg)
```
Creating a plot!
```{r}
geom_point(mapping = aes(x = displ, y = hwy))
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))
```
The plot shows a negative relationship between engine size (displ) and fuel efficiency (hwy). In other words, cars with big engines use more fuel. What does this say about fuel efficiency and engine size?

When youâ€™re creating a plot, you essentially need two attributes of a plot: a geom and aesthetics.
```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, colour = class))
geom_smooth(mappings = aes(x = displ, y = hwy, linetype =drv)) # try smooth line
```
I played around with the different ways of displaying the data and the associated warnings that come up with each of the prompts, in an old R script.
I want to take on board the feedback from the last few modules of refining my script and just do the final and clean versions needed for learning and E-portfolio.

```{r}
# Change point shape by class:
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, shape = class))

# Make all points blue
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), color = "blue")

# Change point colour by class:
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, colour = class))
```
Okay great! I'm getting a good handle on my plots now and how to change aspects of the plot to make it look more aesthetic 

2.22 Transformation and Stats
Let's make a barchart.
```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut))
```
Looks good, I fixed the mistake (typo xx)
```{r}
ggplot(data = diamonds) + 
  stat_count(mapping = aes(x = cut))
```
In general, we can use geoms and stats interchangeably. See above the stat count second chunk, does the same as our geombar function!

Let's learn some more about data frames: 
```{r}
ggplot(data = diamonds) + 
  stat_summary(
    mapping = aes(x = cut, y = depth),
    fun.min = min,
    fun.max = max,
    fun = median
  )
```
```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, colour = cut))
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = cut))

```
```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity))
```
Oooh! This looks great. I actually know these terms of clarity since looking into my moissannite ring!

The ability to make position adjustments is vital, it allows you to customise your plots in three ways, identity (raw data), fill (changes heights) and dodge (which forces ggplot2 to not put things on top of each other).

```{r}
#To alter transparency (alpha)
ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + 
  geom_bar(alpha = 1/5, position = "identity")

#To color the bar outlines with no fill color
ggplot(data = diamonds, mapping = aes(x = cut, colour = clarity)) + 
  geom_bar(fill = NA, position = "identity")
```
```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "fill")
```
I much prefer the solid colour when compared to the transparent columns...
```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "dodge")
```
```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), position = "jitter")
```
We have used jitter previously, great for visualising some types of data!

Okay let's finish up this template since we have had a good play around to help our understanding of what we can change visually within the plots.

Workshop 2: 

